name: Get Addon Catalogue

on:
  workflow_dispatch:
  schedule:
    - cron: "0 20 * * 0"  # Weekly on Sunday 20:00 UTC

permissions:
  contents: write

jobs:
  fetch-addon:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Restore Addon Cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: ${{ runner.temp }}/addon_cache
          key: addon-${{ github.ref_name }}
          restore-keys: |
            addon-${{ github.ref_name }}-
            addon-

      - name: Fetch remote ZIP with ETag + Hash fallback
        id: fetch_zip
        run: |
          set -euo pipefail

          URL="https://addons.freecad.org/addon_catalog_cache.zip"
          ZIP_FILE="addon_catalog_cache.zip"
          CACHE_DIR="${{ runner.temp }}/addon_cache"
          ETAG_FILE="$CACHE_DIR/etag.txt"
          HASH_FILE="$CACHE_DIR/hash.txt"
          DATA_DIR="data"

          mkdir -p "$CACHE_DIR" "$DATA_DIR"

          echo "Checking remote ZIP: $URL"

          get_etag() {
            curl -sI "$URL" | grep -i ETag | sed 's/ETag: //I' | tr -d '\r"'
          }

          download_and_extract() {
            curl -L --fail "$URL" -o "$ZIP_FILE" || { echo "Download failed"; exit 1; }
            unzip -o "$ZIP_FILE" '*.json' -d "$DATA_DIR" >/dev/null || { echo "Unzip failed"; exit 1; }
            unzip -Z1 "$ZIP_FILE" '*.json' || { echo "Unzip failed or no JSON files found"; exit 1; }
          }

          ETAG=$(get_etag)

          if [ -n "${ETAG:-}" ]; then
            echo "ETag found: $ETAG"
            echo "etag=$ETAG" >> "$GITHUB_OUTPUT"

            if [ -f "$ETAG_FILE" && "$(cat "$ETAG_FILE")" == "$ETAG" ]; then
              echo "ETag unchanged. Skipping download."
              echo "changed=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi

            echo "ETag changed or new. Downloading..."
            EXTRACTED_JSON=$(download_and_extract)
            echo "json_file=$DATA_DIR/$EXTRACTED_JSON" >> "$GITHUB_OUTPUT"
            echo "$ETAG" > "$ETAG_FILE"
            echo "changed=true" >> "$GITHUB_OUTPUT"
            exit 0

          else

            echo "No ETag header. Falling back to hash comparison..."
            EXTRACTED_JSON=$(download_and_extract)
            NEW_HASH=$(sha256sum "$ZIP_FILE" | awk '{print $1}')
            echo "Downloaded ZIP hash: $NEW_HASH"
            echo "hash=$NEW_HASH" >> "$GITHUB_OUTPUT"

            if [ -f "$HASH_FILE" && "$(cat "$HASH_FILE")" == "$NEW_HASH" ]; then
              echo "Hash unchanged. Skipping."
              echo "changed=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi

            echo "$NEW_HASH" > "$HASH_FILE"
            echo "json_file=$DATA_DIR/$EXTRACTED_JSON" >> "$GITHUB_OUTPUT"
            echo "changed=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Validate Addon JSON
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          set -euo pipefail

          FILE="${{ steps.fetch_zip.outputs.json_file }}"

          echo "Validating $FILE..."

          jq empty "$FILE" || (echo "Error: $FILE is not valid JSON." && exit 1)

      - name: Cleanup Addon JSON
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          set -euo pipefail

          FILE="${{ steps.fetch_zip.outputs.json_file }}"

          echo "Cleaning JSON: $FILE"

          python3 - "$FILE" <<EOF
          import json
          import sys
          import xml.etree.ElementTree as ET

          file_path = sys.argv[1]

          def extract_metadata(package_xml):
              try:
                  root = ET.fromstring(package_xml)
              except ET.ParseError:
                  return {}

              namespace = {}
              if root.tag.startswith('{'):
                  uri = root.tag.split('}')[0][1:]
                  namespace['namespace'] = uri

                  def namespace_tag(tag):
                      return f"namespace:{tag}"
              else:
                  def namespace_tag(tag):
                      return tag

              def find_text(tag):
                  elem = root.find(namespace_tag(tag), namespace)
                  return elem.text.strip() if elem is not None and elem.text else None

              def find_attr_text(tag, attr=None, attr_value=None):
                  elems = root.findall(namespace_tag(tag), namespace)
                  for elem in elems:
                      if attr and attr_value:
                          if elem.attrib.get(attr) == attr_value:
                              return elem.text.strip() if elem.text else None
                      elif not attr:
                          return elem.text.strip() if elem.text else None
                  return None

              icon = root.findtext(".//namespace:icon", namespaces=namespace) if namespace else root.findtext(".//icon")

              return {
                  "name": find_text("name"),
                  "description": find_text("description"),
                  "version": find_text("version"),
                  "maintainer": find_text("maintainer"),
                  "license": find_text("license"),
                  "icon": icon.strip() if icon else None
              }

          try:
              with open(file_path, "r") as f:
                  data = json.load(f)
          except Exception as e:
              print(f"Failed to load JSON file: {e}", file=sys.stderr)
              sys.exit(1)

          cleaned_data = {}
          for key, entries in data.items():
              cleaned_entries = []
              for entry in entries:
                  metadata = (entry.get("metadata") or {})
                  package_xml = metadata.get("package_xml")
                  cleaned_metadata = extract_metadata(package_xml) if package_xml else {}

                  cleaned_entry = {
                      "repository": entry.get("repository"),
                      "git_ref": entry.get("git_ref"),
                      "last_update_time": entry.get("last_update_time"),
                      "metadata": cleaned_metadata
                  }

                  cleaned_entries.append(cleaned_entry)
              cleaned_data[key] = cleaned_entries

          try:
              with open(file_path, "w") as f:
                  json.dump(cleaned_data, f, indent=2)
          except Exception as e:
              print(f"Failed to write cleaned JSON file: {e}", file=sys.stderr)
              sys.exit(1)
          EOF

      - name: Commit and push cleaned Addon JSON
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add data/addon_catalog_cache.json

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          DATE=$(date -u +"%Y-%m-%d")
          git commit -m "Action: update Addon catalog - $DATE"
          git push

      - name: Save Addon Cache
        id: cache-save
        if: steps.fetch_zip.outputs.changed == 'true'
        uses: actions/cache/save@v4
        with:
          path: ${{ runner.temp }}/addon_cache
          key: addon-${{ github.ref_name }}
