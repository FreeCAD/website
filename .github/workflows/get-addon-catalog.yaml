name: Get Addon Catalogue

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 3'  # Weekly on Wednesday 00:00 UTC

permissions:
  contents: write

jobs:
  fetch-remote-json:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Restore ETag/hash cache
        uses: actions/cache@v4
        with:
          path: .cache
          key: addon-cache-${{ github.ref_name }}
          restore-keys: |
            addon-cache-

      - name: Fetch remote ZIP with ETag + Hash fallback
        id: fetch_zip
        run: |
          set -euo pipefail

          URL="https://addons.freecad.org/addon_catalog_cache.zip"
          ZIP_FILE="addon_catalog_cache.zip"
          ETAG_FILE=".cache/etag.txt"
          HASH_FILE=".cache/hash.txt"
          CACHE_DIR=".cache"
          DATA_DIR="data"

          mkdir -p "$CACHE_DIR" "$DATA_DIR"

          echo "Checking remote ZIP: $URL"

          get_etag() {
            curl -sI "$URL" | grep -i ETag | sed 's/ETag: //I' | tr -d '\r"'
          }

          download_and_extract() {
            curl -L --fail "$URL" -o "$ZIP_FILE"
            unzip -o "$ZIP_FILE" '*.json' -d "$DATA_DIR" >/dev/null
            unzip -Z1 "$ZIP_FILE" '*.json'
          }

          ETAG=$(get_etag || true)

          if [ -n "${ETAG:-}" ]; then
            echo "ETag found: $ETAG"
            echo "etag=$ETAG" >> "$GITHUB_OUTPUT"

            if [ -f "$ETAG_FILE" && "$(cat "$ETAG_FILE")" == "$ETAG" ]; then
              echo "ETag unchanged. Skipping download."
              echo "changed=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi

            echo "ETag changed or new. Downloading..."
            EXTRACTED_JSON=$(download_and_extract)
            echo "json_file=$DATA_DIR/$EXTRACTED_JSON" >> "$GITHUB_OUTPUT"
            echo "$ETAG" > "$ETAG_FILE"
            echo "changed=true" >> "$GITHUB_OUTPUT"
            exit 0
          else
            echo "No ETag header. Falling back to hash comparison..."
            EXTRACTED_JSON=$(download_and_extract)
            NEW_HASH=$(sha256sum "$ZIP_FILE" | awk '{print $1}')
            echo "Downloaded ZIP hash: $NEW_HASH"
            echo "hash=$NEW_HASH" >> "$GITHUB_OUTPUT"

            if [ -f "$HASH_FILE" && "$(cat "$HASH_FILE")" == "$NEW_HASH" ]; then
              echo "Hash unchanged. Skipping."
              echo "changed=false" >> "$GITHUB_OUTPUT"
              exit 0
            fi

            echo "$NEW_HASH" > "$HASH_FILE"
            echo "json_file=$DATA_DIR/$EXTRACTED_JSON" >> "$GITHUB_OUTPUT"
            echo "changed=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Check JSON validity
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          FILE="${{ steps.fetch_zip.outputs.json_file }}"
          echo "Validating $FILE..."
          if ! python3 -m json.tool "$FILE" >/dev/null 2>&1; then
            echo "Error: $FILE is not valid JSON."
            exit 1
          fi

      - name: Cleanup JSON
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          FILE="${{ steps.fetch_zip.outputs.json_file }}"
          echo "Cleaning JSON: $FILE"
          python3 - "$FILE" <<EOF
          import json
          import sys

          file_path = sys.argv[1]

          try:
              with open(file_path, "r") as f:
                  data = json.load(f)
          except Exception as e:
              print(f"Failed to load JSON file: {e}", file=sys.stderr)
              sys.exit(1)

          cleaned_data = {}
          for key, entries in data.items():
              cleaned_entries = []
              for entry in entries:
                  cleaned_entry = {
                      "repository": entry.get("repository"),
                      "last_update_time": entry.get("last_update_time"),
                      "metadata": {
                          "package_xml": (entry.get("metadata") or {}).get("package_xml")
                      }
                  }
                  cleaned_entries.append(cleaned_entry)
              cleaned_data[key] = cleaned_entries

          try:
              with open(file_path, "w") as f:
                  json.dump(cleaned_data, f, indent=2)
          except Exception as e:
              print(f"Failed to write cleaned JSON file: {e}", file=sys.stderr)
              sys.exit(1)
          EOF

      - name: Commit and push updated JSON
        if: steps.fetch_zip.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add data/*.json 2>/dev/null || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git pull --rebase
          DATE=$(date -u +"%Y-%m-%d")
          git commit -m "Action: update Addon catalog - $DATE"
          git push

      - name: Save updated cache
        if: steps.fetch_zip.outputs.changed == 'true'
        uses: actions/cache/save@v4
        with:
          path: .cache
          key: addon-cache-${{ github.ref_name }}
